{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 27182\n",
      "Folder 1 of 28\n",
      "11212\n",
      "Folder 2 of 28\n",
      "2445\n",
      "Folder 3 of 28\n",
      "30008\n",
      "Folder 4 of 28\n",
      "3020\n",
      "Folder 5 of 28\n",
      "3021\n",
      "Folder 6 of 28\n",
      "3023\n",
      "Folder 7 of 28\n",
      "3027\n",
      "Folder 8 of 28\n",
      "3028\n",
      "Folder 9 of 28\n",
      "3029\n",
      "Folder 10 of 28\n",
      "3030\n",
      "Folder 11 of 28\n",
      "3031\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from sklearn import preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from scipy import misc\n",
    "import numpy as np\n",
    "from skimage import color\n",
    "from skimage.color import rgb2gray\n",
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "\n",
    "# Import Data\n",
    "\n",
    "#List folders in the root directory\n",
    "root_path = '/Users/ckruse/Documents/Python/LegoModel/Bricks/'\n",
    "root_folders = listdir(root_path)\n",
    "\n",
    "#Load image names into image_array by iterating through all the folders in the root directory\n",
    "num_img = 0\n",
    "for folder in root_folders:\n",
    "    if isfile(folder) == False:\n",
    "        folder_files = listdir(\"%s%s\" % (root_path, folder))\n",
    "        num_img += len(folder_files)\n",
    "\n",
    "# input image dimensions\n",
    "img_rows = cv2.imread(\"%s%s/%s\" % (root_path, folder, folder_files[1])).shape[1]\n",
    "img_cols = cv2.imread(\"%s%s/%s\" % (root_path, folder, folder_files[1])).shape[0]\n",
    "img_channels = 1\n",
    "\n",
    "#Instantiate main image array\n",
    "brick_stack = np.zeros([img_rows,img_cols])\n",
    "labels_text = []\n",
    "\n",
    "#Iterate through all images to create image array\n",
    "print 'Number of Images:', num_img\n",
    "images = np.zeros((num_img,img_rows,img_cols))\n",
    "i = 0\n",
    "j = 1\n",
    "for folder in root_folders:\n",
    "    if isfile(folder) == False:\n",
    "        print 'Folder', j, 'of', len(root_folders)\n",
    "        print folder\n",
    "        folder_files = listdir(\"%s%s\" % (root_path, folder))\n",
    "        for brick in folder_files:\n",
    "            img = cv2.imread(\"%s%s/%s\" % (root_path, folder, brick))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images[i,:,:] = img\n",
    "            labels_text.append(folder)\n",
    "            i += 1\n",
    "        j += 1\n",
    "\n",
    "print 'Image Array Shape:', images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Crop and resize images\n",
    "image_size = 32\n",
    "patches = np.zeros((num_img,image_size,image_size))\n",
    "i = 0\n",
    "\n",
    "for brick in images:\n",
    "    blurred = blur(brick, 2)\n",
    "    patches[i] = extractpatch(blurred,8)\n",
    "    i +=1\n",
    "    \n",
    "plt.imshow(images_resized[1])\n",
    "plt.show()\n",
    "\n",
    "def blur(image,strength):\n",
    "    blur = cv2.blur(image,(strength,strength))\n",
    "    blur = cv2.convertScaleAbs(blur)\n",
    "    return blur\n",
    "\n",
    "def extractpatch(im,pad):\n",
    "    #Binary Threshold for Image\n",
    "    ret,thresh = cv2.threshold(im,150,255,cv2.THRESH_TOZERO)\n",
    "    #Find contours in threshold image\n",
    "    im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    try: hierarchy = hierarchy[0]\n",
    "    except: hierarchy = []\n",
    "    height, width = im.shape\n",
    "    min_x, min_y = width, height\n",
    "    max_x = max_y = 0\n",
    "    # computes the bounding box for the contour, and draws it on the frame,\n",
    "    for contour, hier in zip(contours, hierarchy):\n",
    "        (x,y,w,h) = cv2.boundingRect(contour)\n",
    "        if w > 5 and w < len(im)-5 and h > 5 and len(im)-5:\n",
    "            side = max(w,h)\n",
    "            if x-pad > 0 and y-pad > 0 and x+pad+side < len(im) and y+pad+side < len(im):\n",
    "                rectx = x-pad\n",
    "                rectx2 = x+pad+side\n",
    "                recty = y-pad\n",
    "                recty2 = y+pad+side\n",
    "            else:\n",
    "                rectx = x\n",
    "                rectx2 = x+side\n",
    "                recty = y\n",
    "                recty2 = y+side\n",
    "            crop = im[recty:recty2,rectx:rectx2]\n",
    "            return cv2.resize(crop, (image_size, image_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Transform text labels from folder names into categorical labels to be\n",
    "# used for the categorical_crossentropy objective\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(labels_text)\n",
    "int_labels = le.transform(labels_text)\n",
    "categorical_labels = to_categorical(int_labels, nb_classes=None)\n",
    "\n",
    "print(categorical_labels.shape)\n",
    "# To get the text label back out, use `le.inverse_transform(3)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split training and validation datasets\n",
    "def splitdata(imageArray, percentage):\n",
    "    img_rows, img_cols = imageArray.shape[1:]\n",
    "    images_dim = np.expand_dims(imageArray, axis=3)\n",
    "\n",
    "    X_train, X_val, Y_train, Y_val = train_test_split(images_dim,categorical_labels, \n",
    "                                                      test_size=percentage, random_state=12)\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_val = X_val.astype('float32')\n",
    "    X_val /= 255\n",
    "\n",
    "    print(X_train.shape[0], 'train samples')\n",
    "    print(X_val.shape[0], 'test samples')\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('Y_train shape:', Y_train.shape)\n",
    "    print('X_val shape:', X_val.shape)\n",
    "    print('Y_val shape:', Y_val.shape)\n",
    "    print('Max Val of Train X', np.max(X_train[0]))\n",
    "    plt.imshow(X_train[1,:,:,0],cmap='gray')\n",
    "    plt.show()\n",
    "    return X_train, X_val, Y_train, Y_val\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = splitdata(patches,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Model Parameters and Training for VGG-style network\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "batch_size = 100\n",
    "nb_classes = categorical_labels.shape[1]\n",
    "nb_epoch = 20\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid',\n",
    "                        input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optional Model Weight Loading\n",
    "#model.load_weights('/Users/ckruse/Documents/Python/LegoModel/model/keras_model_128px_white_weights2.h5')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            nb_epoch=nb_epoch,\n",
    "            verbose=1,\n",
    "            show_accuracy=True,\n",
    "#            validation_split = 0.1,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Model Parameters and Training for LM-style\n",
    "import tensorflow as tf\n",
    "from keras_tqdm import TQDMCallback\n",
    "tf.python.control_flow_ops = tf\n",
    "batch_size = 32\n",
    "nb_classes = 27\n",
    "nb_epoch = 30\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(16, 3, 3, border_mode='valid',\n",
    "                        input_shape=(img_rows,img_cols,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Optional Model Weight Loading\n",
    "model.load_weights('/Users/ckruse/Documents/Python/LegoModel/model/keras_model_32px_LMweights.h5')\n",
    "\n",
    "model.fit(X_train, Y_train,\n",
    "            batch_size=batch_size,\n",
    "            nb_epoch=nb_epoch,\n",
    "            verbose=0,\n",
    "            show_accuracy=True,\n",
    "#            validation_split = 0.1,\n",
    "            validation_data=(X_val, Y_val),\n",
    "            shuffle=True,\n",
    "            callbacks=[TQDMCallback()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save Model\n",
    "from keras.models import load_model\n",
    "#model.summary()\n",
    "model.save('/Users/ckruse/Documents/Python/LegoModel/model/keras_model_32px_LMarch.h5')\n",
    "model.save_weights('/Users/ckruse/Documents/Python/LegoModel/model/keras_model_32px_LMweights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Visualize a set of test predictions\n",
    "\n",
    "num_images = 5\n",
    "image_set = np.random.randint(0, X_train.shape[0], num_images)\n",
    "#image_set = range(1000,1010)\n",
    "print(image_set.shape)\n",
    "n = 0\n",
    "\n",
    "for image in image_set:\n",
    "    itemindex = np.where(Y_train[image]==1)\n",
    "    print(\"True Block ID: \", le.inverse_transform(itemindex))\n",
    "    prediction = model.predict(X_train[image_set,:,:,:],batch_size=2,verbose=False)\n",
    "    print(\"Predicted Block ID: \", le.inverse_transform(np.argmax(prediction[n])))\n",
    "    print(\"Confidence: \", np.amax(prediction[n]))\n",
    "    n = n+1\n",
    "    plt.imshow(X_train[image,:,:,0], cmap='gray')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate some statistics on prediction success rates\n",
    "success = np.zeros(Y_val.shape[1])\n",
    "num = np.zeros(Y_val.shape[1])\n",
    "confidence = np.zeros(Y_val.shape[1])\n",
    "prediction = model.predict(X_val[range(0,Y_val.shape[0]),:,:,:],batch_size=5,verbose=True)\n",
    "\n",
    "for image in range(0,Y_val.shape[0]):\n",
    "    itemindex = np.where(Y_val[image]==1)[0]\n",
    "\n",
    "    # Get count of items in the dataset\n",
    "    num[itemindex] += 1\n",
    "    \n",
    "    # Check the total number of correct predictions\n",
    "    truth = le.inverse_transform(itemindex[0])\n",
    "    model_out = le.inverse_transform(np.argmax(prediction[image]))\n",
    "    if truth == model_out:\n",
    "        success[itemindex] += 1\n",
    "        # Compile total sum of confidences\n",
    "        confidence[itemindex] += np.amax(prediction[image])\n",
    "\n",
    "success_rate = np.divide(success,num)\n",
    "confidence_rate = np.divide(confidence,num)\n",
    "for i in range(0,Y_val.shape[1]):\n",
    "    print(\"Success Rate:\", le.inverse_transform(i), 100*round(success_rate[i],3))\n",
    "for i in range(0,Y_val.shape[1]):\n",
    "    print(\"Mean Correct Confidence:\", le.inverse_transform(i), 100*round(confidence_rate[i],3))\n",
    "for i in range(0,Y_val.shape[1]):\n",
    "    print(\"Number of Samples:\", le.inverse_transform(i), num[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "test_brick_images = np.zeros([img_rows,img_cols])\n",
    "test_brick = misc.imread('/Users/ckruse/Downloads/brick_5mod2.jpg')\n",
    "image_size = 32\n",
    "\n",
    "im = test_brick\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.blur(im,(4,4))\n",
    "blur = cv2.convertScaleAbs(blur)\n",
    "ret,thresh = cv2.threshold(blur,150,255,cv2.THRESH_TOZERO)\n",
    "#plt.imshow(thresh,cmap='gray')\n",
    "#plt.show()\n",
    "im2, contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#print(contours)\n",
    "try: hierarchy = hierarchy[0]\n",
    "except: hierarchy = []\n",
    "height, width = im.shape\n",
    "min_x, min_y = width, height\n",
    "max_x = max_y = 0\n",
    "pad = 8\n",
    "# computes the bounding box for the contour, and draws it on the frame,\n",
    "for contour, hier in zip(contours, hierarchy):\n",
    "    (x,y,w,h) = cv2.boundingRect(contour)\n",
    "    if w > 5 and w < len(im)-5 and h > 5 and len(im)-5:\n",
    "        side = max(w,h)\n",
    "        if x-pad > 0 and y-pad > 0 and x+pad+side < len(im) and y+pad+side < len(im):\n",
    "            rectx = x-pad\n",
    "            rectx2 = x+pad+side\n",
    "            recty = y-pad\n",
    "            recty2 = y+pad+side\n",
    "        else:\n",
    "            rectx = x\n",
    "            rectx2 = x+side\n",
    "            recty = y\n",
    "            recty2 = y+side\n",
    "        crop = im[recty:recty2,rectx:rectx2]\n",
    "        img = cv2.resize(crop, (image_size, image_size))\n",
    "        test_brick = img\n",
    "\n",
    "test_brick = np.rollaxis(test_brick, 0,0)\n",
    "test_image = np.dstack((test_brick_images, test_brick))\n",
    "test_brick_images = np.dstack((test_brick_images, test_brick))\n",
    "#test_brick_images = np.delete(test_brick_images,0,axis=2)\n",
    "test_brick_images = np.expand_dims(test_brick_images, axis=3)\n",
    "test_brick_images = np.rollaxis(test_brick_images,2,0)\n",
    "print('Prediction:',le.inverse_transform(np.argmax(model.predict(test_brick_images,batch_size=1,verbose=False)[1])))\n",
    "print('Confidence:', np.amax(model.predict(test_brick_images,batch_size=1,verbose=False)[1]))\n",
    "\n",
    "plt.imshow(test_brick,cmap='gray')\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# for a in range(750,760):\n",
    "#     print(Y_train[a])\n",
    "#     print(X_train.shape)\n",
    "#     itemindex = np.where(Y_train[a]==1)\n",
    "#     print(le.inverse_transform(itemindex))\n",
    "#     print(images[:,:,a].shape)\n",
    "#     plt.imshow(images[:,:,a])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# img_num = 100\n",
    "# std_x = np.zeros(len(images[:,0,img_num]))\n",
    "# std_y = np.zeros(len(images[:,0,img_num]))\n",
    "# for i in range(0,len(images[:,0,img_num])):\n",
    "#     std_x[i] = np.std(images[i,:,img_num])\n",
    "# for j in range(0,len(images[0,:,img_num])):\n",
    "#     std_y[i] = np.std(images[:,j,img_num])\n",
    "\n",
    "# max_x = np.argmax(std_x)\n",
    "# max_y = np.argmax(std_y)\n",
    "# print(max_x, max_y)\n",
    "# test_img = images[:,:,img_num]\n",
    "# test_img[max_x,:] = 255\n",
    "# test_img[:,max_y] = 255\n",
    "# plt.imshow(test_img[:,:])\n",
    "# plt.show()\n",
    "# plt.imshow(images[:,:,img_num])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# from skimage.feature import blob_dog, blob_log, blob_doh\n",
    "# from skimage.color import rgb2gray\n",
    "# from skimage import feature\n",
    "\n",
    "# img_num = 3000\n",
    "# edges = feature.canny(images[:,:,img_num],sigma=2)\n",
    "\n",
    "# plt.imshow(edges)\n",
    "# plt.show()\n",
    "# plt.imshow(images[:,:,img_num])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import math\n",
    "# im = cv2.imread('/Users/ckruse/Downloads/hybrid_brick.jpg',0)\n",
    "# plt.imshow(im)\n",
    "# plt.show()\n",
    "# print(im.shape)\n",
    "# im2, contours, hierarchy = cv2.findContours(im,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# print(contours)\n",
    "# try: hierarchy = hierarchy[0]\n",
    "# except: hierarchy = []\n",
    "# height, width = im.shape\n",
    "# min_x, min_y = width, height\n",
    "# max_x = max_y = 0\n",
    "\n",
    "# # computes the bounding box for the contour, and draws it on the frame,\n",
    "# for contour, hier in zip(contours, hierarchy):\n",
    "#     (x,y,w,h) = cv2.boundingRect(contour)\n",
    "#     print(x,y,w,h)\n",
    "#     min_x, max_x = min(x, min_x), max(x+w, max_x)\n",
    "#     min_y, max_y = min(y, min_y), max(y+h, max_y)\n",
    "#     if w > 10 and h > 10:\n",
    "#         cv2.rectangle(im, (x,y), (x+w,y+h), (255, 0, 0), 2)\n",
    "\n",
    "# if max_x - min_x > 0 and max_y - min_y > 0:\n",
    "#     cv2.rectangle(im, (min_x, min_y), (max_x, max_y), (255, 0, 0), 2)\n",
    "\n",
    "# plt.imshow(im)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# im = cv2.imread('/Users/ckruse/Documents/Unity/Lego Sim II/screenshots/3027 (2017-03-19_10-21-057211).png',0)\n",
    "\n",
    "# thresh_med = int(np.median(im))\n",
    "# thresh_med = 110\n",
    "# ret,thresh = cv2.threshold(im,thresh_med,255,0)\n",
    "# for i in range(0,len(thresh)):\n",
    "#     for j in range(0,len(thresh)):\n",
    "#         if min(thresh[i][:]) == 0:\n",
    "#             if min(thresh[:][j]) == 0:\n",
    "#                 bounds_y = [i,j]\n",
    "#                 break\n",
    "# for i in range(0,len(thresh)):\n",
    "#     for j in range(0,len(thresh)):\n",
    "#         if min(thresh[:][j]) == 0:\n",
    "#             if min(thresh[i][:]) == 0:\n",
    "#                 bounds_x = [i,j]\n",
    "#                 break\n",
    "# print(bounds_x,bounds_y)\n",
    "# im3,contours, hierarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# plt.imshow(im3)\n",
    "# plt.show()\n",
    "# plt.imshow(im,cmap='Greys_r')\n",
    "# #plt.imshow(im3,cmap='Greys_r')\n",
    "# x = []\n",
    "# y = []\n",
    "# w = []\n",
    "# h = []\n",
    "# for i in range(0, len(contours)):\n",
    "#     if (i % 2 == 0):\n",
    "#        cnt = contours[i]\n",
    "\n",
    "#        #mask = np.zeros(im2.shape,np.uint8)\n",
    "#        #cv2.drawContours(mask,[cnt],0,255,-1)\n",
    "#        x.append(cv2.boundingRect(cnt)[0])\n",
    "#        y.append(cv2.boundingRect(cnt)[1])\n",
    "#        w.append(cv2.boundingRect(cnt)[2])\n",
    "#        h.append(cv2.boundingRect(cnt)[3])\n",
    "\n",
    "# index_max = np.argmax(w)\n",
    "# cv2.rectangle(im,(min_xy[0],min_xy[1]),(min_xy[0]+1,min_xy[0]+1),(0,0,0),2)\n",
    "# #cv2.rectangle(im,(x[index_max],y[index_max]),(x[index_max]+w[index_max],y[index_max]+h[index_max]),(0,0,0),2)\n",
    "# plt.imshow(im,cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Import Data\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 128, 128\n",
    "img_channels = 1\n",
    "\n",
    "#Create main image array\n",
    "images = np.zeros([img_rows,img_cols])\n",
    "labels_text = []\n",
    "\n",
    "#List folders in the root directory\n",
    "root_path = '/Users/ckruse/Documents/Python/LegoModel/Bricks/'\n",
    "root_folders = listdir(root_path)\n",
    "\n",
    "#Load images into image_array by iterating through all the folders in the root directory\n",
    "for folder in root_folders:\n",
    "    if isfile(folder) == False:\n",
    "        print(folder)\n",
    "        folder_files = listdir(\"%s%s\" % (root_path, folder))\n",
    "        for brick in folder_files:\n",
    "            img = cv2.imread(\"%s%s/%s\" % (root_path, folder, brick))\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            imagesa = np.dstack((imagesa, img))\n",
    "            labels_text.append(folder)\n",
    "\n",
    "imagesa = np.delete(images,0,axis=2)\n",
    "print(imagesa.shape)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(dict([(layer.name, layer) for layer in model.layers]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
